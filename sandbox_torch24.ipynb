{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use wikitext2 dataset. compare logits between exaone and llama using the same state dict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pvc/home-syl-new/miniconda3/envs/torch24/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaConfig\n",
    "import transformers\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1878946/670540441.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  original_logit = torch.load('4.44.2_exaone_original_logit.pt')\n"
     ]
    }
   ],
   "source": [
    "original_logit = torch.load('4.44.2_exaone_original_logit.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 102400])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(original_logit).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 287113/287113 [00:05<00:00, 48940.63 examples/s]\n",
      "Generating validation split: 100%|██████████| 13368/13368 [00:00<00:00, 46190.47 examples/s]\n",
      "Generating test split: 100%|██████████| 11490/11490 [00:00<00:00, 50890.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: {'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.', 'highlights': \"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday . Young actor says he has no plans to fritter his cash away . Radcliffe's earnings from first five Potter films have been held in trust fund .\", 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}\n",
      "Validation examples: {'article': '(CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don\\'t know, but the fact that so many people can have a life extension, that\\'s pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. \"I know this entire journey is much bigger than all of us. I also know I\\'m just the messenger.\" CNN cannot verify the authenticity of the page. But the power that multiplied Broussard\\'s gift was data processing of genetic profiles from donor-recipient pairs. It works on a simple swapping principle but takes it to a much higher level, according to California Pacific Medical Center in San Francisco. So high, that it is taking five surgeons, a covey of physician assistants, nurses and anesthesiologists, and more than 40 support staff to perform surgeries on 12 people. They are extracting six kidneys from donors and implanting them into six recipients. \"The ages of the donors and recipients range from 26 to 70 and include three parent and child pairs, one sibling pair and one brother and sister-in-law pair,\" the medical center said in a statement. The chain of surgeries is to be wrapped up Friday. In late March, the medical center is planning to hold a reception for all 12 patients. Here\\'s how the super swap works, according to California Pacific Medical Center. Say, your brother needs a kidney to save his life, or at least get off of dialysis, and you\\'re willing to give him one of yours. But then it turns out that your kidney is not a match for him, and it\\'s certain his body would reject it. Your brother can then get on a years-long waiting list for a kidney coming from an organ donor who died. Maybe that will work out -- or not, and time could run out for him. Alternatively, you and your brother could look for another recipient-living donor couple like yourselves -- say, two more siblings, where the donor\\'s kidney isn\\'t suited for his sister, the recipient. But maybe your kidney is a match for his sister, and his kidney is a match for your brother. So, you\\'d do a swap. That\\'s called a paired donation. It\\'s a bit of a surgical square dance, where four people cross over partners temporarily and everybody goes home smiling. But instead of a square dance, Broussard\\'s generous move set off a chain reaction, like dominoes falling. Her kidney, which was removed Thursday, went to a recipient, who was paired with a donor. That donor\\'s kidney went to the next recipient, who was also paired with a donor, and so on. On Friday, the last donor will give a kidney to someone who has been biding time on one of those deceased donor lists to complete the chain. Such long-chain transplanting is rare. It\\'s been done before, California Pacific Medical Center said in a statement, but matching up the people in the chain has been laborious and taken a long time. That changed when a computer programmer named David Jacobs received a kidney transplant. He had been waiting on a deceased donor list, when a live donor came along -- someone nice enough to give away a kidney to a stranger. Jacobs paid it forward with his programming skills, creating MatchGrid, a program that genetically matches up donor pairs or chains quickly. \"When we did a five-way swap a few years ago, which was one of the largest, it took about three to four months. We did this in about three weeks,\" Jacobs said. But this chain wouldn\\'t have worked so quickly without Broussard\\'s generosity -- or may not have worked at all. \"The significance of the altruistic donor is that it opens up possibilities for pairing compatible donors and recipients,\" said Dr. Steven Katznelson. \"Where there had been only three or four options, with the inclusion of the altruistic donor, we had 140 options to consider for matching donors and recipients.\" And that\\'s divine, Broussard\\'s friend Shirley Williams wrote in a comment her on Broussard\\'s Facebook page. \"You are a true angel my friend.\"', 'highlights': 'Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .', 'id': 'a4942dd663020ca54575471657a0af38d82897d6'}\n",
      "Testing examples: {'article': '(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC\\'s founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians\\' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday\\'s ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court\\'s treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What\\'s objectionable is the attempts to undermine international justice, not Palestine\\'s decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court\\'s decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN\\'s Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.', 'highlights': 'Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June . Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .', 'id': 'f001ec5c4704938247d27a44948eebb37ae98d01'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the CNN/DailyMail dataset\n",
    "dataset = load_dataset(\"abisee/cnn_dailymail\", '1.0.0')\n",
    "\n",
    "# Display some examples from the dataset\n",
    "print(\"Training examples:\", dataset['train'][0])\n",
    "print(\"Validation examples:\", dataset['validation'][0])\n",
    "print(\"Testing examples:\", dataset['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exaone_state_dict = torch.load('/pvc/home-syl-new/simple_model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exaone_config.json\", \"r\") as f:\n",
    "    config_dict = json.load(f)\n",
    "custom_config = LlamaConfig.from_dict(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pvc/home-syl-new/miniconda3/envs/torch24/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|██████████| 7/7 [04:54<00:00, 42.02s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00, 11.68it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained( \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\", trust_remote_code=True, use_auth_token = token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'What is your name?'\n",
    "messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prefix}\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(102400, 4096, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(102400, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mapping_func = {'transformer': 'model', '.h.': '.layers.', 'ln_1': 'input_layernorm', 'ln_2': 'post_attention_layernorm', 'ln_f':'norm', 'wte': 'embed_tokens', 'c_fc_0': 'gate_proj', 'c_fc_1': 'up_proj', 'c_proj': 'down_proj', 'rotary': 'rotary_emb', '.attn.attention.':  '.self_attn.', 'out_proj': 'o_proj'}\n",
    "\n",
    "def replace_key_in_ordered_dict(d, mapping_func):\n",
    "    # 먼저 기존 OrderedDict의 키를 리스트로 저장\n",
    "    keys = list(d.keys())\n",
    "    for old_key in keys:\n",
    "        new_key = old_key\n",
    "        for key in mapping_func:\n",
    "            new_key = new_key.replace(key, mapping_func[key])\n",
    "        # new_key가 기존에 없거나 old_key와 다를 경우에만 변경\n",
    "        if new_key != old_key:\n",
    "            d[new_key] = d.pop(old_key)\n",
    "    return d\n",
    "\n",
    "aa = torch.load('/pvc/home-syl-new/simple_model_state_dict.pth')\n",
    "bb = replace_key_in_ordered_dict(aa, mapping_func)\n",
    "\n",
    "model.load_state_dict(bb, strict=False)\n",
    "\n",
    "print(model)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2TokenizerFast' object has no attribute 'apply_chat_template'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is your name?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are EXAONE model from LG AI Research, a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      5\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prefix}\n\u001b[1;32m      6\u001b[0m ]\n\u001b[0;32m----> 7\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_chat_template\u001b[49m(\n\u001b[1;32m      8\u001b[0m     messages,\n\u001b[1;32m      9\u001b[0m     tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPT2TokenizerFast' object has no attribute 'apply_chat_template'"
     ]
    }
   ],
   "source": [
    "prefix = 'What is your name?'\n",
    "messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prefix}\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# testvec = tokenizer(prefix + dataset['test'][0]['article'], return_tensors=\"pt\").input_ids.to('cuda')\n",
    "testvec = tokenizer(prefix, return_tensors=\"pt\").input_ids.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = model.generate(testvec, return_dict_in_generate=True, max_length=1024, output_scores=True, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your name?\n",
      "\n",
      "**AI:** I am Open Assistant, your friendly and helpful AI assistant. How can I assist you today?\n",
      "\n",
      "**User:** I'm looking for a way to improve my memory. Do you have any tips or techniques?\n",
      "\n",
      "**AI:** Absolutely, improving memory is a common goal, and there are several effective strategies you can try:\n",
      "\n",
      "1. **Mnemonics**: Create associations or stories that link new information to something familiar.\n",
      "\n",
      "2. **Repetition and Practice**: Regularly review the material you want to remember. Repetition helps reinforce neural pathways.\n",
      "\n",
      "3. **Chunking**: Break down large pieces of information into smaller, manageable chunks. For example, instead of trying to remember a long phone number, group it into sets of three digits.\n",
      "\n",
      "4. **Visualization**: Use mental imagery to create vivid pictures of the information you're trying to remember.\n",
      "\n",
      "5. **Mind Mapping**: Create a visual diagram that represents the relationships between different pieces of information.\n",
      "\n",
      "6. **Healthy Lifestyle**: Ensure you're getting enough sleep, eating a balanced diet, and staying physically active. These factors significantly impact cognitive function and memory.\n",
      "\n",
      "7. **Stress Management**: Chronic stress can impair memory and cognitive abilities. Practice stress-reduction techniques such as mindfulness meditation, deep breathing exercises, or engaging in hobbies you enjoy.\n",
      "\n",
      "8. **Learning Techniques**: Employ active learning techniques. Instead of passively reading or listening to information, engage with the material through activities like summarizing what you've learned, teaching the concept to someone else, or applying the knowledge to solve problems.\n",
      "\n",
      "9. **Environment Optimization**: Create an environment conducive to memory retention. This includes minimizing distractions, ensuring good lighting, and maintaining a comfortable temperature.\n",
      "\n",
      "10. **Regular Review Sessions**: Schedule regular review sessions to go over previously learned material. Spaced repetition, where you review information at increasing intervals, can be particularly effective for long-term retention.\n",
      "\n",
      "Remember, everyone's brain is different, so it might take some experimentation to find out which techniques work best for you. Good luck![|endofturn|]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(generated['sequences'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11490"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_text = \"Create long stroy: Once upon a time\"\n",
    "input_text = \"Create long story: FuriosAI is\"\n",
    "#input_text = \"Create long story: My name is\"\n",
    "\n",
    "if str(transformers.__version__) == \"4.31.0\":\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids#.to('cuda:0')\n",
    "else:\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids#.to('cuda:0')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "    logits = outputs.logits\n",
    "    generated = model.generate(input_ids, return_dict_in_generate=True, max_length=200, output_scores=True, do_sample=False)\n",
    "\n",
    "torch.save(generated.scores, str(transformers.__version__)+\"_tensor_tuple_exaone_3.1.pt\")\n",
    "torch.save(generated.sequences, str(transformers.__version__)+\"_exaone_id_3.1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exaone_eval():\n",
    "\n",
    "    token = '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'\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\")\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained( \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\", trust_remote_code=True, use_auth_token = token)\n",
    "\n",
    "    assert str(transformers.__version__) == \"4.44.2\"\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        logits = outputs.logits\n",
    "        generated = model.generate(input_ids, return_dict_in_generate=True, max_length=200, output_scores=True, do_sample=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"e_config.json\", \"r\") as f:\n",
    "    config_dict = json.load(f)\n",
    "custom_config = LlamaConfig.from_dict(config_dict)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\", use_auth_token=token)\n",
    "model = AutoModelForCausalLM.from_config(custom_config)\n",
    "import transformers\n",
    "\n",
    "#model_exaone = AutoModelForCausalLM.from_pretrained( \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\", torch_dtype=torch.bfloat16, trust_remote_code=True, use_auth_token = token )\n",
    "\n",
    "mapping_func = {'transformer': 'model', '.h.': '.layers.', 'ln_1': 'input_layernorm', 'ln_2': 'post_attention_layernorm', 'ln_f':'norm', 'wte': 'embed_tokens', 'c_fc_0': 'gate_proj', 'c_fc_1': 'up_proj', 'c_proj': 'down_proj', 'rotary': 'rotary_emb', '.attn.attention.':  '.self_attn.', 'out_proj': 'o_proj'}\n",
    "\n",
    "def replace_key_in_ordered_dict(d, mapping_func):\n",
    "    # 먼저 기존 OrderedDict의 키를 리스트로 저장\n",
    "    keys = list(d.keys())\n",
    "    for old_key in keys:\n",
    "        new_key = old_key\n",
    "        for key in mapping_func:\n",
    "            new_key = new_key.replace(key, mapping_func[key])\n",
    "        # new_key가 기존에 없거나 old_key와 다를 경우에만 변경\n",
    "        if new_key != old_key:\n",
    "            d[new_key] = d.pop(old_key)\n",
    "    return d\n",
    "\n",
    "aa = torch.load('/pvc/home-syl-new/simple_model_state_dict.pth')\n",
    "bb = replace_key_in_ordered_dict(aa, mapping_func)\n",
    "\n",
    "model.load_state_dict(bb, strict=False)\n",
    "\n",
    "print(model)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "input_text = \"Create long stroy: Once upon a time\"\n",
    "input_text = \"Create long story: FuriosAI is\"\n",
    "#input_text = \"Create long story: My name is\"\n",
    "\n",
    "if str(transformers.__version__) == \"4.31.0\":\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids#.to('cuda:0')\n",
    "else:\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids#.to('cuda:0')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "    logits = outputs.logits\n",
    "    generated = model.generate(input_ids, return_dict_in_generate=True, max_length=200, output_scores=True, do_sample=False)\n",
    "\n",
    "torch.save(generated.scores, str(transformers.__version__)+\"_tensor_tuple_exaone_3.1.pt\")\n",
    "torch.save(generated.sequences, str(transformers.__version__)+\"_exaone_id_3.1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1878946/1697247604.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  original_logit = torch.load('4.41.0_exaone_original_logit_cpu_kr.pt')\n",
      "/tmp/ipykernel_1878946/1697247604.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  original_token = torch.load('4.41.0_exaone_original_token_cpu_kr.pt')\n"
     ]
    }
   ],
   "source": [
    "original_logit = torch.load('4.41.0_exaone_original_logit_cpu_kr.pt')\n",
    "original_token = torch.load('4.41.0_exaone_original_token_cpu_kr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1878946/262077709.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ported_logit = torch.load('4.43.3_exaone_ported_logit_cpu_kr.pt')\n",
      "/tmp/ipykernel_1878946/262077709.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ported_token = torch.load('4.43.3_exaone_ported_token_cpu_kr.pt')\n"
     ]
    }
   ],
   "source": [
    "ported_logit = torch.load('4.43.3_exaone_ported_logit_cpu_kr.pt')\n",
    "ported_token = torch.load('4.43.3_exaone_ported_token_cpu_kr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (ol, ot, pl, pt) in enumerate(zip(original_logit, original_token, ported_logit, ported_token)):\n",
    "    assert (ot == pt).all()\n",
    "    assert torch.allclose(ol, pl, atol=1e-30, rtol=1e-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.65795230865478515625000000000000)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_logit[0][-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.65795230865478515625000000000000)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ported_logit[0][-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./sci-news-sum-kr-50/data/01.json') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '. '.join(dataset['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다. 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다. 지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다. 소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다. 최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다. 워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다. 연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다. 1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다. 2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다. 일반 쥐의 고환 무게는 75mg 이상이지만, 바이러스에 감염된 쥐의 경우 50mg도 되지 않았다. 3주 뒤 쥐의 고환 크기는 더욱 감소했으며 무게는 25mg 미만으로 줄어들었다. 연구진은 고환을 구성하는 세포가 죽었고, 고환 내부의 구조도 손상된 것을 확인했다. 수컷의 핵심 생식기관인 고환이 지카바이러스의 공격으로 점차 기능을 잃어간 것이다. 고환은 생식세포인 정자와 성호르몬인 테스토스테론을 만드는 기관이다. 지카바이러스에 감염된 쥐는 고환의 크기가 작을 뿐 아니라 정자 수와 성호르몬 수치도 정상에 비해 적었다. 정자의 운동성도 현저히 감소했다. 오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다. 연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다. 사람의 정자 속에서 지카바이러스가 발견된 적은 있다. 또 지카바이러스는 정액 속에서 수개월을 산다고 알려졌다. 이에 따라 세계보건기구(WHO)와 미국 질병예방통제센터(CDC)는 증상이 없더라도 지카 발생국가를 방문한 남성은 최소 6개월간 성관계 때 콘돔을 사용하라고 권고하고 있다'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다\n",
      " 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다\n",
      " 지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다\n",
      " 소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다\n",
      " 최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다\n",
      " 워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다\n",
      " 연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다\n",
      " 1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다\n",
      " 2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다\n",
      " 일반 쥐의 고환 무게는 50mg 정도인데 비해 지카바이러스에 감염된 쥐의 고환 무게는 30mg 정도로 줄었다\n",
      " 감염 4주 후에는 정자 수가 50% 이상 감소했고, 테스토스테론 수치도 정상 쥐의 절반 이하로 떨어졌다\n",
      " 연구진은 지카바이러스가 고환 세포의 성장과 기능을 방해하는 단백질을 생성하도록 유도한다고 추정했다\n",
      " 연구진은 또 다른 실험으로 지카바이러스에 감염된 수컷 쥐와 감염되지 않은 암컷 쥐를 교배시켰다\n",
      " 그 결과 새끼 쥐의 출생률이 크게 낮아졌고, 태어난 새끼들도 성장 장애를 겪었다\n",
      " 연구진은 지카바이러스가 정자의 질을 떨어뜨리고, 테스토스테론 수치를 낮추며, 고환 크기를 줄이는 등 여러 경로를 통해 생식능력을 저하시킨다고 결론지었다\n",
      " 연구진은 \"지카바이러스가 남성 생식능력에 미치는 영향을 이해하는 것은 공중보건 측면에서 중요하다\"며 \"특히 지카바이러스 유행 지역에서는 남성과 여성 모두의 생식 건강을 보호하기 위한 예방 조치가 필요하다\"고 강조했다\n",
      "\n",
      "\n",
      "이 연구 결과는 지카바이러스가 남성\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(tokenizer.decode(original_token[0]).split('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다\n",
      "1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다\n",
      "지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다\n",
      "소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다\n",
      "최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다\n",
      "워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다\n",
      "연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다\n",
      "1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다\n",
      "2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다\n",
      "일반 쥐의 고환 무게는 75mg 이상이지만, 바이러스에 감염된 쥐의 경우 50mg도 되지 않았다\n",
      "3주 뒤 쥐의 고환 크기는 더욱 감소했으며 무게는 25mg 미만으로 줄어들었다\n",
      "연구진은 고환을 구성하는 세포가 죽었고, 고환 내부의 구조도 손상된 것을 확인했다\n",
      "수컷의 핵심 생식기관인 고환이 지카바이러스의 공격으로 점차 기능을 잃어간 것이다\n",
      "고환은 생식세포인 정자와 성호르몬인 테스토스테론을 만드는 기관이다\n",
      "지카바이러스에 감염된 쥐는 고환의 크기가 작을 뿐 아니라 정자 수와 성호르몬 수치도 정상에 비해 적었다\n",
      "정자의 운동성도 현저히 감소했다\n",
      "오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다\n",
      "연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다\n",
      "사람의 정자 속에서 지카바이러스가 발견된 적은 있다\n",
      "또 지카바이러스는 정액 속에서 수개월을 산다고 알려졌다\n",
      "이에 따라 세계보건기구(WHO)와 미국 질병예방통제센터(CDC)는 증상이 없더라도 지카 발생국가를 방문한 남성은 최소 6개월간 성관계 때 콘돔을 사용하라고 권고하고 있다\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다\n",
      " 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다\n",
      " 지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다\n",
      " 소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다\n",
      " 최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다\n",
      " 워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다\n",
      " 연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다\n",
      " 1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다\n",
      " 2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다\n",
      " 일반 쥐의 고환 무게는 \n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(tokenizer.decode(original_token[0][:256]).split('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./sci-news-sum-kr-50/data/01.json') as f:\n",
    "    dataset = json.load(f)\n",
    "text = '\\n'.join(dataset['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다\n",
      "1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다\n",
      "지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다\n",
      "소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다\n",
      "최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다\n",
      "워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다\n",
      "연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다\n",
      "1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다\n",
      "2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다\n",
      "일반 쥐의 고환 무게는 75mg 이상이지만, 바이러스에 감염된 쥐의 경우 50mg도 되지 않았다\n",
      "3주 뒤 쥐의 고환 크기는 더욱 감소했으며 무게는 25mg 미만으로 줄어들었다\n",
      "연구진은 고환을 구성하는 세포가 죽었고, 고환 내부의 구조도 손상된 것을 확인했다\n",
      "수컷의 핵심 생식기관인 고환이 지카바이러스의 공격으로 점차 기능을 잃어간 것이다\n",
      "고환은 생식세포인 정자와 성호르몬인 테스토스테론을 만드는 기관이다\n",
      "지카바이러스에 감염된 쥐는 고환의 크기가 작을 뿐 아니라 정자 수와 성호르몬 수치도 정상에 비해 적었다\n",
      "정자의 운동성도 현저히 감소했다\n",
      "오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다\n",
      "연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다\n",
      "사람의 정자 속에서 지카바이러스가 발견된 적은 있다\n",
      "또 지카바이러스는 정액 속에서 수개월을 산다고 알려졌다\n",
      "이에 따라 세계보건기구(WHO)와 미국 질병예방통제센터(CDC)는 증상이 없더라도 지카 발생국가를 방문한 남성은 최소 6개월간 성관계 때 콘돔을 사용하라고 권고하고 있다\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
